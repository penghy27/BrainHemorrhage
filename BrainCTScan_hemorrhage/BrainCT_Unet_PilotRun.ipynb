{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### The segmentation model employed in this study was a U-Net architecture"
      ],
      "metadata": {
        "id": "uVuOzDrn_pqh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR6N7G16-1eX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from tqdm.auto import tqdm\n",
        "import imgaug.augmenters as iaa\n",
        "import imgaug as ia\n",
        "from tensorflow.keras import *\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data set**"
      ],
      "metadata": {
        "id": "0Z2NhnDyDnlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parent_folder = \"### Your parent folder ###\"\n",
        "img_subfolders = [\"epidural\", \"intraparenchymal\",  \"subdural\", \"intraventricular\"]\n",
        "mask_subfolders = [\"epidural_mask\", \"intraparenchymal_mask\", \"subdural_mask\", \"intraventricular_mask\"]\n",
        "\n",
        "def load_data(parent_folder, img_subfolders, mask_subfolders):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for img_subfolder, mask_subfolder in zip(img_subfolders, mask_subfolders):\n",
        "        img_folder_path = os.path.join(parent_folder, img_subfolder)\n",
        "        mask_folder_path = os.path.join(parent_folder, mask_subfolder)\n",
        "\n",
        "        for filename in os.listdir(img_folder_path):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(img_folder_path, filename)\n",
        "                mask_filename = filename.replace(\"merged\", \"mask\").replace(\".jpg\", \"_mask.jpg\")\n",
        "                mask_path = os.path.join(mask_folder_path, mask_filename)\n",
        "\n",
        "                img = img_to_array(load_img(img_path, target_size=(256, 256))) / 255.0\n",
        "                mask = img_to_array(load_img(mask_path, target_size=(256, 256), color_mode=\"grayscale\")) / 255.0\n",
        "\n",
        "                images.append(img)\n",
        "                masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "\n",
        "images, masks = load_data(parent_folder, img_subfolders, mask_subfolders)\n"
      ],
      "metadata": {
        "id": "Lz1XqWiX_mFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display original image and corresponding mask**"
      ],
      "metadata": {
        "id": "7rlmkZGhDe4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Randomly choose one index\n",
        "random_index = random.randint(0, len(images) - 1)\n",
        "\n",
        "# Choose images and corresponding mask\n",
        "random_image = images[random_index]\n",
        "random_mask = masks[random_index]\n",
        "\n",
        "# Show original image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(random_image)\n",
        "plt.title('Original Image')\n",
        "\n",
        "# Show mask image\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(random_mask[:, :, 0], cmap='gray')  # 使用灰度顯示遮罩\n",
        "plt.title('Mask Image')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lnzxyQp1AoWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check data distribution**"
      ],
      "metadata": {
        "id": "AkVZS2LFDapM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function checked data distribution\n",
        "def check_data_distribution(parent_folder, subfolders):\n",
        "    class_counts = {}\n",
        "\n",
        "    for subfolder in subfolders:\n",
        "        folder_path = os.path.join(parent_folder, subfolder)\n",
        "        class_name = subfolder.split(\"_\")[0]  # Extract type name，like \"normal\"、\"epidural\" ...etc\n",
        "\n",
        "        # Calculate the counts of each class\n",
        "        class_counts[class_name] = len(os.listdir(folder_path))\n",
        "\n",
        "\n",
        "\n",
        "    # Visualization\n",
        "    plt.bar(class_counts.keys(), class_counts.values())\n",
        "    plt.title('Class Distribution')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Number of Samples')\n",
        "    plt.show()\n",
        "\n",
        "# Data Districution\n",
        "check_data_distribution(parent_folder, img_subfolders)"
      ],
      "metadata": {
        "id": "pwFgQpoFBPWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data set**"
      ],
      "metadata": {
        "id": "01ivgCjCDUXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset to Training/validation/test set\n",
        "train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(train_images, train_masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check each set size\n",
        "print(f\"Training set size：{len(train_images)}\")\n",
        "print(f\"Validation set size：{len(val_images)}\")\n",
        "print(f\"Test set size：{len(test_images)}\")"
      ],
      "metadata": {
        "id": "zPjgXYdtCx-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build U-Net Model**"
      ],
      "metadata": {
        "id": "NPwT6tsDDPRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 256\n",
        "\n",
        "# Method 1: Enlarge feature maps by UpSampling2D\n",
        "input_layer = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# Encoder\n",
        "c1 = layers.Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same')(input_layer)\n",
        "l = layers.MaxPool2D()(c1)\n",
        "c2 = layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same')(l)\n",
        "l = layers.MaxPool2D()(c2)\n",
        "c3 = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(l)\n",
        "l = layers.MaxPool2D()(c3)\n",
        "c4 = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(l)\n",
        "\n",
        "# Decoder\n",
        "l = layers.concatenate([layers.UpSampling2D()(c4),\n",
        "                        c3], axis=-1)\n",
        "l = layers.Conv2D(filters=32, kernel_size=(2,2), activation='relu', padding='same')(l)\n",
        "l = layers.concatenate([layers.UpSampling2D()(l),\n",
        "                        c2], axis=-1)\n",
        "l = layers.Conv2D(filters=24, kernel_size=(2,2), activation='relu', padding='same')(l)\n",
        "l = layers.concatenate([layers.UpSampling2D()(l),\n",
        "                        c1], axis=-1)\n",
        "l = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(l)\n",
        "l = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(l)\n",
        "\n",
        "# Output\n",
        "output_layer = layers.Conv2D(filters=1,\n",
        "                             kernel_size=1,\n",
        "                             activation='sigmoid')(l)\n",
        "\n",
        "model = models.Model(input_layer, output_layer)"
      ],
      "metadata": {
        "id": "Eqc4JrkLDJ44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model training**"
      ],
      "metadata": {
        "id": "w9UhYD7HDvgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize Metrics: Dice coefficient\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
        "\n",
        "# Customize Dice Loss\n",
        "def dice_loss(y_true, y_pred):\n",
        "    dice = dice_coef(y_true, y_pred)\n",
        "    return 1 - dice"
      ],
      "metadata": {
        "id": "Yu132anTDy7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizers.legacy.Adam(),\n",
        "              loss='binary_crossentropy', # keras.losses.BinaryCrossentropy()\n",
        "            #   loss=dice_loss,\n",
        "              metrics=[dice_coef])"
      ],
      "metadata": {
        "id": "KryH7foRD0gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_saver = callbacks.ModelCheckpoint('3unet_seg.h5',\n",
        "                                         save_best_only=True)\n",
        "earlystop = callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                    patience=5)"
      ],
      "metadata": {
        "id": "05vuSQ5vD5Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs = model.fit(train_images, train_masks,\n",
        "                 validation_data=(val_images, val_masks),\n",
        "                 epochs=100,\n",
        "                 callbacks = [weight_saver, earlystop])"
      ],
      "metadata": {
        "id": "aaDV8AzND_Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = logs.history\n",
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.savefig('/Users/peng.hsiaoyu/Downloads/BrainCTScan/loss_plot_20231204.png') # Adjust the filename and format as needed\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history['dice_coef'])\n",
        "plt.plot(history['val_dice_coef'])\n",
        "plt.title('Dice')\n",
        "plt.savefig('/Users/peng.hsiaoyu/Downloads/BrainCTScan/dice_plot_20231204.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aXxdyQcUEKky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "He42uECdELjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict test set\n",
        "predictions = model.predict(test_images)\n"
      ],
      "metadata": {
        "id": "XvwkgNcRENZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Dice coefficient and Dice loss\n",
        "dice_coefficient = dice_coef(test_masks, predictions)\n",
        "dice_loss_value = dice_loss(test_masks, predictions)\n",
        "\n",
        "# Print the results\n",
        "print(f'Dice Coefficient on Test Set: {dice_coefficient:.4f}')\n",
        "print(f'Dice Loss on Test Set: {dice_loss_value:.4f}')"
      ],
      "metadata": {
        "id": "ANCKa57lEVDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize original image, actual mask, and predicted mask\n",
        "index = random.randint(0, len(test_images) - 1)\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(test_images[index])\n",
        "plt.title('Original Image')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(test_masks[index][:, :, 0], cmap='gray')\n",
        "plt.title('Actual Mask')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(predictions[index][:, :, ], cmap='gray')\n",
        "plt.title('Predicted Mask')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2kU6tuoaEekw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}